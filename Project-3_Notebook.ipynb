{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c51008ab",
   "metadata": {},
   "source": [
    "<h1><center>Lab 3: Clustering</center></h1>\n",
    "<h3><center>A Deeper Analysis of Covid-19 Data</center></h3>\n",
    "<p><center>DS 7331</center></p>\n",
    "<p><center>Created by Sadik Aman, Dawn Bowerman, Zachary Harris, Alexandre Jasserme</center></p>\n",
    "\n",
    "<p><center>Sections of this code was adapted from: \n",
    "    <li>https://github.com/jakemdrew/DataMiningNotebooks</li>\n",
    "    <li> https://scikit-learn.org/stable/auto_examples/linear_model/plot_theilsen.html</li>\n",
    "    <li> https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RANSACRegressor.html </li>\n",
    "    <li> https://machinelearningmastery.com/random-forest-ensemble-in-python/ </li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67912ba8",
   "metadata": {},
   "source": [
    "## Business Understanding 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3aa351",
   "metadata": {},
   "source": [
    "### Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?)\n",
    "\n",
    "This dataset is published in the 'Our World in Data' website which is a collection of existing datasets. \n",
    "Source: https://github.com/owid/covid-19-data/tree/master/public/data \n",
    "Citation:\n",
    "Hannah Ritchie, Edouard Mathieu, Lucas Rodés-Guirao, Cameron Appel, Charlie Giattino, Esteban Ortiz-Ospina, Joe Hasell, Bobbie Macdonald, Diana Beltekian and Max Roser (2020) - \"Coronavirus Pandemic (COVID-19)\". Published online at OurWorldInData.org. Retrieved from: 'https://ourworldindata.org/coronavirus' [Online Resource]\n",
    "\n",
    ">This dataset was partially obtained from:\n",
    "The Covid-19 Data Repository which is for the Coronavirus Visual Dashboard by the Center for Systems Science and Engineering at Johns Hopkins University.  The data has been accumulated from many official sources, which are documented on the github, since January 22, 2020 on confirmed Covid-19 cases and deaths for all countries.  https://github.com/CSSEGISandData/COVID-19\n",
    "Other attributes were from official government reports documented in the codebook. There were originally 67 attributes and 154,105 records.  They are presented below with descriptions from the website:\n",
    "\n",
    ">**Confirmed cases**                                                      \n",
    "total_cases: \t                               \t\tTotal confirmed cases of COVID-19,\n",
    "new_cases: \t\t\t\tNew confirmed cases of COVID-19<br>\n",
    "new_cases_smoothed:\t\t\tNew confirmed cases of COVID-19 (7-day smoothed)<br>\n",
    "total_cases_per_million: \t\t\tTotal confirmed cases of COVID-19 per 1,000,000 people<br>\n",
    "new_cases_per_million: \t\t\tNew confirmed cases of COVID-19 per 1,000,000 people<br>\n",
    "new_cases_smoothed_per_million: \t\tNew confirmed cases of COVID-19 (7-day smoothed) per 1,000,000 people<br>\n",
    "\n",
    "\n",
    ">**Confirmed deaths**<br>\n",
    "total_deaths: \t\t\t\tTotal deaths attributed to COVID-19<br>\n",
    "new_deaths: \t\t\t\tNew deaths attributed to COVID-19<br>\n",
    "new_deaths_smoothed: \t\t\tNew deaths attributed to COVID-19 (7-day smoothed)<br>\n",
    "total_deaths_per_million: \t\t\tTotal deaths attributed to COVID-19 per 1,000,000 people<br>\n",
    "new_deaths_per_million: \t\t\tNew deaths attributed to COVID-19 per 1,000,000 people<br>\n",
    "new_deaths_smoothed_per_million: \t\tNew deaths attributed to COVID-19 (7-day smoothed) per 1,000,000 people<br>\n",
    "\n",
    "\n",
    "\n",
    ">**Excess mortality**<br>\n",
    "excess_mortality: \t\t\t\tPercentage difference between the reported number of weekly or monthly deaths in 2020–2021 and the \t\t\t\t\t\t\tprojected number of deaths for the same period based on previous years.<br> \n",
    "excess_mortality_cumulative: \t\t\tPercentage difference between the cumulative number of deaths since 1 January 2020 and the cumulative \t\t\t\t\t\tprojected deaths for the same period based on previous years.<br> \n",
    "excess_mortality_cumulative_absolute: \t\tCumulative difference between the reported number of deaths since 1 January 2020 and the projected \t\t\t\t\t\t\tnumber of deaths for the same period based on previous years.<br> \n",
    "excess_mortality_cumulative_per_million: \tCumulative difference between the reported number of deaths since 1 January 2020 and the projected \t\t\t\t\t\t\tnumber of deaths for the same period based on previous years, per million people.<br> \n",
    "\n",
    "\n",
    ">**Hospital & ICU**<br>\n",
    "icu_patients: \t\t\t\tNumber of COVID-19 patients in intensive care units (ICUs) on a given day<br>\n",
    "icu_patients_per_million: \t\t\tNumber of COVID-19 patients in intensive care units (ICUs) on a given day per 1,000,000 people<br>\n",
    "hosp_patients: \t\t\t\tNumber of COVID-19 patients in hospital on a given day<br>\n",
    "hosp_patients_per_million: \t\t\tNumber of COVID-19 patients in hospital on a given day per 1,000,000 people<br>\n",
    "weekly_icu_admissions: \t\t\tNumber of COVID-19 patients newly admitted to intensive care units (ICUs) in a given week<br>\n",
    "weekly_icu_admissions_per_million: \t\tNumber of COVID-19 patients newly admitted to intensive care units (ICUs) in a given week per 1,000,000 \t\t\t\t\tpeople<br>\n",
    "weekly_hosp_admissions: \t\t\tNumber of COVID-19 patients newly admitted to hospitals in a given week<br>\n",
    "weekly_hosp_admissions_per_million: \t\tNumber of COVID-19 patients newly admitted to hospitals in a given week per 1,000,000 people<br>\n",
    "\n",
    "\n",
    ">**Policy responses**<br>\n",
    "stringency_index: \t\t\t\tGovernment Response Stringency Index: composite measure based on 9 response indicators including \t\t\t\t\t\t\tschool closures, workplace closures, and travel bans, rescaled to a value from 0 to 100 (100 = strictest \t\t\t\t\t\t\tresponse)<br>\n",
    "\n",
    ">**Reproduction rate**<br>\n",
    "reproduction_rate:\t\t\t\tReal-time estimate of the effective reproduction rate (R) of COVID-19.\n",
    "The basic reproduction number, also known as the R or R0, is the average number of people one person with an infectious disease will likely infect in the future.\n",
    "<br>\n",
    "\n",
    "\n",
    ">**Tests & positivity**<br>\n",
    "total_tests: \t\t\t\tTotal tests for COVID-19<br>\n",
    "new_tests: \t\t\t\tNew tests for COVID-19 (only calculated for consecutive days)<br>\n",
    "total_tests_per_thousand: \t\t\tTotal tests for COVID-19 per 1,000 people<br>\n",
    "new_tests_per_thousand: \t\t\tNew tests for COVID-19 per 1,000 people<br>\n",
    "new_tests_smoothed: \t\t\tNew tests for COVID-19 (7-day smoothed). For countries that don't report testing data on a daily basis, we \t\t\t\t\t\t\tassume that testing changed equally on a daily basis over any periods in which no data was reported. This \t\t\t\t\t\t\tproduces a complete series of daily figures, which is then averaged over a rolling 7-day window<br>\n",
    "new_tests_smoothed_per_thousand: \t\tNew tests for COVID-19 (7-day smoothed) per 1,000 people<br>\n",
    "positive_rate: \t\t\t\tThe share of COVID-19 tests that are positive, given as a rolling 7-day average (this is the inverse of \t\t\t\t\ttests_per_case)<br>\n",
    "tests_per_case: \t\t\t\tTests conducted per new confirmed case of COVID-19, given as a rolling 7-day average (this is the inverse of \t\t\t\t\tpositive_rate)<br>\n",
    "tests_units: \t\t\t\tUnits used by the location to report its testing data<br>\n",
    "\n",
    "\n",
    ">**Vaccinations**<br>\n",
    "total_vaccinations: \t\t\t\tTotal number of COVID-19 vaccination doses administered<br>\n",
    "people_vaccinated: \t\t\t\tTotal number of people who received at least one vaccine dose<br>\n",
    "people_fully_vaccinated: \t\t\tTotal number of people who received all doses prescribed by the vaccination protocol<br>\n",
    "total_boosters: \t\t\t\tTotal number of COVID-19 vaccination booster doses administered (doses administered beyond the \t\t\t\t\t\t\tnumber prescribed by the vaccination protocol)<br>\n",
    "new_vaccinations: \t\t\t\tNew COVID-19 vaccination doses administered (only calculated for consecutive days)<br>\n",
    "new_vaccinations_smoothed: \t\t\tNew COVID-19 vaccination doses administered (7-day smoothed). For countries that don't report \t\t\t\t\t\t\tvaccination data on a daily basis, we assume that vaccination changed equally on a daily basis over any \t\t\t\t\t\t\tperiods in which no data was reported. This produces a complete series of daily figures, which is then \t\t\t\t\t\t\taveraged over a rolling 7-day window<br>\n",
    "total_vaccinations_per_hundred: \t\tTotal number of COVID-19 vaccination doses administered per 100 people in the total population<br>\n",
    "people_vaccinated_per_hundred: \t\tTotal number of people who received at least one vaccine dose per 100 people in the total population<br>\n",
    "people_fully_vaccinated_per_hundred: \t\tTotal number of people who received all doses prescribed by the vaccination protocol per 100 people in the \t\t\t\t\ttotal population<br>\n",
    "total_boosters_per_hundred: \t\t\tTotal number of COVID-19 vaccination booster doses administered per 100 people in the total population<br>\n",
    "new_vaccinations_smoothed_per_million: \tNew COVID-19 vaccination doses administered (7-day smoothed) per 1,000,000 people in the total \t\t\t\t\t\t\tpopulation<br>\n",
    "new_people_vaccinated_smoothed: \t\tDaily number of people receiving their first vaccine dose (7-day smoothed)<br>\n",
    "new_people_vaccinated_smoothed_per_hundred: \tDaily number of people receiving their first vaccine dose (7-day smoothed) per 100 people in the total \t\t\t\t\t\t\tpopulation<br>\n",
    "\n",
    "\n",
    ">**Others**<br>\n",
    "iso_code: \t\t\t\t\tISO 3166-1 alpha-3 – three-letter country codes<br>\n",
    "continent: \t\t\t\t\tContinent of the geographical location<br>\n",
    "location: \t\t\t\t\tGeographical location<br>\n",
    "date: \t\t\t\t\tDate of observation<br>\n",
    "population: \t\t\t\tPopulation (latest available values)<br> \n",
    "population_density: \t\t\t\tNumber of people divided by land area, measured in square kilometers, most recent year available<br>\n",
    "median_age: \t\t\t\tMedian age of the population, UN projection for 2020<br>\n",
    "aged_65_older: \t\t\t\tShare of the population that is 65 years and older, most recent year available<br>\n",
    "aged_70_older: \t\t\t\tShare of the population that is 70 years and older in 2015<br>\n",
    "gdp_per_capita: \t\t\t\tGross domestic product at purchasing power parity (constant 2011 international dollars), most recent year \t\t\t\t\t\tavailable<br>\n",
    "extreme_poverty: \t\t\t\tShare of the population living in extreme poverty, most recent year available since 2010<br>\n",
    "cardiovasc_death_rate: \t\t\tDeath rate from cardiovascular disease in 2017 (annual number of deaths per 100,000 people)<br>\n",
    "diabetes_prevalence: \t\t\tDiabetes prevalence (% of population aged 20 to 79) in 2017<br>\n",
    "female_smokers: \t\t\t\tShare of women who smoke, most recent year available<br>\n",
    "male_smokers: \t\t\t\tShare of men who smoke, most recent year available<br>\n",
    "handwashing_facilities: \t\t\tShare of the population with basic handwashing facilities on premises, most recent year available<br>\n",
    "hospital_beds_per_thousand: \t\t\tHospital beds per 1,000 people, most recent year available since 2010<br>\n",
    "life_expectancy: \t\t\t\tLife expectancy at birth in 2019<br>\n",
    "human_development_index: \t\t\tA composite index measuring average achievement in three basic dimensions of human development—a \t\t\t\t\t\t\tlong and healthy life, knowledge and a decent standard of living. Values for 2019, imported from \t\t\t\t\t\t\thttp://hdr.undp.org/en/indicators/137506<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b577f26b",
   "metadata": {},
   "source": [
    "### How would you measure the effectiveness of a good algorithm?<br>\n",
    "In order to evaluate the precision and accuracy of our derived model, we can use Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and cross-validation. Given that we have a limited number of outliers in the dataset, we feel that using **RMSE with 10-fold cross-validation** is an appropriate choice. While RMSE is more sensitive to outliers than the MAE, the RMSE performs very well and is generally preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c2dd52",
   "metadata": {},
   "source": [
    "### Why does your chosen validation method make sense for this specific dataset and the stakeholders needs? <br>\n",
    "bla bla "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba35b159",
   "metadata": {},
   "source": [
    "## Data Understanding 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3cb5b1",
   "metadata": {},
   "source": [
    "### Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file.  \n",
    "\n",
    "The source dataset contains 154105 observations and 67 attributes. As there are attributes in this dataset that are updated daily, the data used in this report was downloaded from the source on January 15, 2022 at 1:00 PM CST. In order to analyze the data for this report, some attributes in the dataset were manipulated or eliminated. Table 1 outlines the final list of attributes used for this report and descriptions for each.\n",
    "\n",
    "\n",
    "\n",
    "<p><center>Table 1: Attributes</center></p>\n",
    "\n",
    "| Variable Name                  | Data Type | Description                                                                                                                                                                                                                                                                                                                                           |\n",
    "|--------------------------------|-----------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| continent                      | object    | Continent of the geographical location                                                                                                                                                                                                                                                                                                                |\n",
    "| location                       | object    | Geographical location                                                                                                                                                                                                                                                                                                                                 |\n",
    "| date                           | object    | Date of observation                                                                                                                                                                                                                                                                                                                                   |\n",
    "| new_cases                      | numerical | New confirmed cases of COVID-19                                                                                                                                                                                                                                                                                                                       |\n",
    "| new_cases_smoothed             | numerical | New confirmed cases of COVID-19 (7-day smoothed)                                                                                                                                                                                                                                                                                                      |\n",
    "| new_deaths                     | numerical | New deaths attributed to COVID-19                                                                                                                                                                                                                                                                                                                     |\n",
    "| new_deaths_smoothed            | numerical | New deaths attributed to COVID-19 (7-day smoothed)                                                                                                                                                                                                                                                                                                    |\n",
    "| reproduction_rate              | numerical | Real-time estimate of the effective reproduction rate (R) of COVID-19                                                                                                                                                                                                                                                                                 |\n",
    "| new_tests                      | numerical | New tests for COVID-19 (only calculated for consecutive days)                                                                                                                                                                                                                                                                                         |\n",
    "| new_tests_smoothed             | numerical | New tests for COVID-19 (7-day smoothed).  For countries that don't report testing data on a  daily basis, we assume that testing changed equally  on a daily basis over any periods in which no data was reported.  This produces a complete series of daily figures,  which is then averaged over a rolling 7-day window                             |\n",
    "| positive_rate                  | numerical | The share of COVID-19 tests that are positive,  given as a rolling 7-day average (this is the inverse of tests_per_case)                                                                                                                                                                                                                              |\n",
    "| tests_per_case                 | numerical | Tests conducted per new confirmed case of COVID-19, given as a rolling 7-day average  (this is the inverse of positive_rate)                                                                                                                                                                                                                          |\n",
    "| people_fully_vaccinated        | numerical | Total number of people who received all doses prescribed by the vaccination protocol                                                                                                                                                                                                                                                                  |\n",
    "| new_vaccinations               | numerical | New COVID-19 vaccination doses administered (only calculated for consecutive days)                                                                                                                                                                                                                                                                    |\n",
    "| new_vaccinations_smoothed      | numerical | New COVID-19 vaccination doses administered (7-day smoothed).  For countries that don't report vaccination data on a daily basis,  we assume that vaccination changed equally on a daily basis over any periods in which  no data was reported. This produces a complete series of daily figures, which is  then averaged over a rolling 7-day window |\n",
    "| new_people_vaccinated_smoothed | numerical | Daily number of people receiving their first vaccine dose (7-day smoothed)                                                                                                                                                                                                                                                                            |\n",
    "| stringency_index               | numerical | Government Response Stringency Index: composite measure based on 9 response  indicators including school closures, workplace closures,  and travel bans, rescaled to a value from 0 to 100 (100 = strictest response)                                                                                                                                 |\n",
    "| population                     | numerical | Population                                                                                                                                                                                                                                                                                                                                            |\n",
    "| population_density             | numerical | Number of people divided by land area, measured in square kilometers,  most recent year available                                                                                                                                                                                                                                                     |\n",
    "| median_age                     | numerical | Median age of the population, UN projection for 2020                                                                                                                                                                                                                                                                                                  |\n",
    "| aged_65_older                  | numerical | Share of the population that is 65 years and older, most recent year available                                                                                                                                                                                                                                                                        |\n",
    "| aged_70_older                  | numerical | Share of the population that is 70 years and older in 2015                                                                                                                                                                                                                                                                                            |\n",
    "| gdp_per_capita                 | numerical | Gross domestic product at purchasing power parity  (constant 2011 international dollars),  most recent year available                                                                                                                                                                                                                                 |\n",
    "| extreme_poverty                | numerical | Share of the population living in extreme poverty,  most recent year available since 2010                                                                                                                                                                                                                                                             |\n",
    "| cardiovasc_death_rate          | numerical | Death rate from cardiovascular disease in 2017 (annual number of deaths per 100,000 people)                                                                                                                                                                                                                                                           |\n",
    "| diabetes_prevalence            | numerical | Diabetes prevalence (% of population aged 20 to 79) in 2017                                                                                                                                                                                                                                                                                           |\n",
    "| female_smokers                 | numerical | Share of women who smoke, most recent year available                                                                                                                                                                                                                                                                                                  |\n",
    "| male_smokers                   | numerical | Share of men who smoke, most recent year available                                                                                                                                                                                                                                                                                                    |\n",
    "| handwashing_facilities         | numerical | Share of the population with basic handwashing facilities on premises,  most recent year available                                                                                                                                                                                                                                                    |\n",
    "| hospital_beds_per_thousand     | numerical | Hospital beds per 1,000 people, most recent year available since 2010                                                                                                                                                                                                                                                                                 |\n",
    "| life_expectancy                | numerical | Life expectancy at birth in 2019                                                                                                                                                                                                                                                                                                                      |\n",
    "| human_development_index        | numerical | A composite index measuring average achievement in three basic  dimensions of human development—a long and healthy life,  knowledge and a decent standard of living.                                                                                                                                                                                  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed3296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "#Libraries\n",
    "import plotly\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import time\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import random as rd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression, TheilSenRegressor\n",
    "from sklearn.linear_model import RANSACRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from yellowbrick.regressor import PredictionError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469ba3d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/owid-covid-data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3740/214223001.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Loading in the CSV file and displaying the resulting dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcovid_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/owid-covid-data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcovid_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachLearn7331\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachLearn7331\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachLearn7331\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachLearn7331\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachLearn7331\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachLearn7331\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachLearn7331\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\MachLearn7331\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/owid-covid-data.csv'"
     ]
    }
   ],
   "source": [
    "#Loading in the CSV file and displaying the resulting dataframe\n",
    "covid_data = pd.read_csv('data/owid-covid-data.csv')\n",
    "covid_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e919cf43",
   "metadata": {},
   "source": [
    "The description of all 67 fields of the data attributes can be found at https://ourworldindata.org/coronavirus. We only used 37 of the 67 attributes because a lot of the attributes were daily total which didn't work well for predictions and they had daily current counts that worked better.  Also, some of the attributes , like tests_units would not be relevant to predictions.  A few of the fields, such as excess_mortality, total_boosters, weekly_hospital_admissions, and weekly_icu admissions had so many missing entries that they were useless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6a56c8",
   "metadata": {},
   "source": [
    "|                                               |       Eliminated Attributes               |                                                     |   |\n",
    "|-----------------------------------------------|:-----------------------------------------:|-----------------------------------------------------|---|\n",
    "| #0 iso_code                                   | #21    weekly_icu_admissions              | #33  tests_units                                    |   |\n",
    "| #4 total_cases                                | #22    weekly_icu_admissions_per_million  | #34 total_vaccinations                              |   |\n",
    "| #7 total_deaths                               | #23  weekly_hosp_admissions               | #35 people_vaccinated                               |   |\n",
    "| #10 total_cases_per_million                   | #24    weekly_hosp_admissions_per_million | #36 people_fully_vaccinated                         |   |\n",
    "| #11 new_cases_per_million                     | #25 new_tests                             | #37 total_boosters                                  |   |\n",
    "| #12 new_cases_smoothed_per_million            | #26 total_tests                           | #38 new_vaccinations                                |   |\n",
    "| #13 total_deaths_per_million                  | #27 total_tests_per_thousand              | #40   total_vaccinations_per_hundred                |   |\n",
    "| #14 total_death_per_million                   | #28  new_tests_per_thousand               | #41 people_vaccinated_per_hundred                   |   |\n",
    "| #15 new_deaths_smoothed_per_million           | #29 new_tests_smoothed                    | #42    people_fully_vaccinated_per_hundred          |   |\n",
    "| #17    icu_patients                           | #30    new_tests_smoothed_per_thousand    | #43    total_boosters_per_hundred                   |   |\n",
    "| #18 icu_patients_per_million                  | #31 positive_rate                         | #44    new_vaccinations_smoothed_per_million        |   |\n",
    "| #19    hosp_patients                          | #32 tests_per_case                        | #46   new_people_vaccinated_smoothed_per_hundred    |   |\n",
    "| #20 hosp_patients_per_million                 | #57 female_smokers                        | #54 extreme_poverty                                 |   |\n",
    "| #58 male_smokers                              | #64  excess_mortality_cumulative          | #66   excess_mortality_cumulative_per_million       |   |\n",
    "| #63    excess_mortality_cumulative_absolute   | #65  excess_mortality                     |                                                     |   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da5b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original Source Data\n",
    "\n",
    "covid_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the variables\n",
    "\n",
    "# Dropping attributes that are highly correlated or have many missing values (based on lab 1 analysis)\n",
    "covid_df = covid_data.drop(covid_data.columns[[0,4,7,10,11,12,13,14,15,17,18,19,20,21,22,23,24,25,26,\n",
    "                                                     27,28,29,30,31,32,\n",
    "                                                     33,34,35,36,37,38,40,41,42,43,44,46,54,57,58,63,64,65,66]], axis=1)\n",
    "\n",
    "# Removing dates before July 1st, 2021 and after December 31, 2021 to have a more manageable data set (with still more than 30,000 rows)\n",
    "covid_df = covid_df[covid_df.date >= '2021-07-01']\n",
    "covid_df = covid_df[covid_df.date <= '2021-12-31']\n",
    "\n",
    "# Removing Oceania because it has a lot of missing values (based on lab 1 analysis)\n",
    "covid_df = covid_df[~covid_df.continent.isin(['Oceania'])]\n",
    "\n",
    "# Removing several countries with a lot of missing values (based on lab 1 analysis)\n",
    "covid_df = covid_df[~covid_df.location.isin(['Turkmenistan', 'Northern Cyprus', 'Sint Maarten (Dutch part)', 'Jersey', 'Guernsey', 'Laos', 'Macao', 'Timor', 'Vatican', 'Saint Kitts and Nevis', 'Saint Vincent and the Grenadines', 'Saint Pierre and Miquelon', 'St. Helena', 'Cook Island', 'Greenland', 'Gibraltar', 'Anguilla'])]\n",
    "\n",
    "# Handling missing values: our models cannot be trained on data set with missing data.\n",
    "# We already removed columns and rows that have many missing data and we will impute the remaining missing data.\n",
    "# Since we are dealing with data collected over time, we have to account for the temporal autocorrelation. \n",
    "# So, instead of using the column mean or median to fill-in the missing data, we chose to interpolate it.\n",
    "covid_df = covid_df.interpolate()\n",
    "\n",
    "# Creating a new category variable for stringency index that can be used for categorization\n",
    "covid_df['stringency_range'] = pd.cut(covid_df.stringency_index,[0,10,20,30,40,50,60,70,80,90,100],10,labels=['0-10','10-20','20-30','30-40','40-50','50-60','60-70','70-80','80-90','90-100']) # creating a new variable\n",
    "\n",
    "# Creating a new category variable for new_cases that can be used for categorization\n",
    "covid_df['new_cases_range'] = pd.qcut(covid_df.new_cases, 3, labels=[\"low\", \"medium\", \"high\"])\n",
    "\n",
    "# Creating a new category variable for new_deaths that can be used for categorization\n",
    "covid_df['new_deaths_range'] = pd.qcut(covid_df.new_deaths, 3, labels=[\"low\", \"medium\", \"high\"])\n",
    "\n",
    "# Ideas from https://scikit-learn.org/stable/modules/cross_validation.html#timeseries-cv\n",
    "# Sorting data frame by date column\n",
    "covid_df['date'] = pd.to_datetime(covid_df['date']) # Converting data columnn to datetime\n",
    "covid_df = covid_df.sort_values(by='date', ascending=True)\n",
    "\n",
    "# Performing one hot encoding of the location variable - we will not use it in the final model, the explanation is in the next cell\n",
    "categ_features = ['location'];\n",
    "one_hot_df = pd.concat([pd.get_dummies(covid_df[col],prefix=col) for col in categ_features], axis=1)\n",
    "\n",
    "# Dropping more attributes that are highly correlated or have many missing values (based on lab 1 analysis) or that will not be used for this analysis (stringency_range and new_deaths_range)\n",
    "covid_df = covid_df.drop([\"new_deaths_smoothed\",\n",
    "                    \"new_cases\",\n",
    "                    \"new_cases_smoothed\",\n",
    "                    \"continent\",\n",
    "                    \"location\",\n",
    "                    \"stringency_range\",\n",
    "                    \"date\",\n",
    "                    \"new_people_vaccinated_smoothed\",\n",
    "                    \"population_density\",\n",
    "                    \"aged_70_older\",\n",
    "                    \"new_deaths_range\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99f8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We investigated one hot encoding of the location variable. \n",
    "# Unfortunately, this increase greatly the size of the model (it would have more than 200 rows) so we decided to not use the location variable in the final model\n",
    "one_hot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541380c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Size of the final dataset showing that is has more than 30,000 rows and 15 columns:', covid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b5c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the data set:\n",
    "covid_df.info() #Dataset being analyzed (MAIN DATASET)\n",
    "covid_df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0394ab1a",
   "metadata": {},
   "source": [
    "## Data Understanding 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53569f4e",
   "metadata": {},
   "source": [
    "#### Visualize the important attributes appropriately.  Important: Provide an interpretation for any charts or graphs.  <br>\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c230b33",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e37aa4",
   "metadata": {},
   "source": [
    "### Train and adjust parameters <br>\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7288f2f",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92b2d1f",
   "metadata": {},
   "source": [
    "### Evaluate and Compare  <br>\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2896747",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfb94ff",
   "metadata": {},
   "source": [
    "### Visualize results <br>\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea87b06",
   "metadata": {},
   "source": [
    "##  Modeling and Evaluation 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19590ed6",
   "metadata": {},
   "source": [
    "### Summarize the Ramifications <br>\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69c8625",
   "metadata": {},
   "source": [
    "## Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e479eb",
   "metadata": {},
   "source": [
    "### How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)?  <br>\n",
    "\n",
    "The models created for this analysis use different prediction methods to determine the range of new cases and the number of new deaths resulting from Covid-19. While many of these models may have already been created, there is still a lot unknown about Covid-19. So, companies and organizations are eager to obtain any data and information they can get on Covid-19. If companies have a lot of data, they may want to study different models and outcomes, potentially making our models appealing to different organizations. Companies and organizations such as the CDC, Baylor Scott and White, and other participants in the health industry may be interested in these types of models. They may even improve accuracy of the models by incorporating and adding their own data. \n",
    "\n",
    "Also, these models could be very useful for life insurance companies so that they can adjust premiums and underwriting. These insurance companies are significantly impacted by Covid-19: \n",
    "\"Life insurance policies paid out over $90 billion in 2020, a 15.4% increase over 2019. That’s the largest year-over-year increase since the 1918 influenza pandemic.\" (source: https://fortune.com/2021/12/09/life-insurance-payouts-2020-record-high-covid/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4888d0",
   "metadata": {},
   "source": [
    "### How would your deploy your model for interested parties? <br>\n",
    "\n",
    "The dataset used for this analysis was partially obtained from The Covid-19 Data Repository, which is for the Coronavirus Visual Dashboard by the Center for Systems Science and Engineering at Johns Hopkins University, and many other official sources. Since the pandemic's beginning, many people and groups within the health sector have been contributing and building datasets to study Covid-19. Like these groups, our model could also be deployed to GitHub, and we could allow the public to download, execute, and improve our models. To specifically deploy our models to interested parties, we could collaborate with non-profit public health organizations that collaborate with hospitals, primary care facilities, and other health establishments. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21752319",
   "metadata": {},
   "source": [
    "### What other data should be collected? <br>\n",
    "\n",
    "Other data that should be collected may include observations for the variants of Covid-19. Since the viruses continues to mutate, there may be other features that could be implemented in the model. Futhermore, we may discover that some features in the original model are no longer relevant.\n",
    "Another data category that could be useful for analyzing Covid-19 could be symptoms. Throughout the pandemic, different people have been experiencing many different symptoms and enduring many different outcomes from the virus. By analyzing these symptoms, we may be able to better predict the outcomes of getting infected by Covid-19. \n",
    "\n",
    "Exploring granular observations for a particular geographic location, such as the United States could be another area of interest.\n",
    "\n",
    "Lastly, to better understand the impact of Covid, collecting disability data to understand the magnitude of long Covid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3e6f16",
   "metadata": {},
   "source": [
    " ### How often would the model need to be updated, etc.? <br>\n",
    "    \n",
    "Every day, new data is being created, particularly for Covid-19. As a result, predictive models need to be updated. As we learn more about Covid-19, many new variables may become relevant. While predictive models are capable of handling a lot of new data, too much buildup of new data may cause the models to lose their effectiveness over time. After a month, quarter, or year, updating predictive models with new data is probably necessary. In order to determine how often a model should be updated, one has to consider how often the data is changing and how often decisions are being made off the model. If data is changing very rapidly or decisions are being made often, frequent updates may be best. When updating the model, you should be sure to investigate the new data, adjust the model, and reevaluate any assumptions made in the creation process.     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bba7787",
   "metadata": {},
   "source": [
    "## Exceptional Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3bf20d",
   "metadata": {},
   "source": [
    "### You have free reign to provide additional analyses or combine analyses. <br>\n",
    "\n",
    "bla bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae71b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
